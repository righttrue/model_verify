{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' # font 설정\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False # '-' 부호 인식 설정\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data_list = glob.glob(\"../DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/*csv\") # observational data file list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 바이살라 수집 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data_list_vi = glob.glob(\"../DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/*vai*csv\") # observational data file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data_list_lufft = glob.glob(\"../DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/*lufft*csv\") # observational data file list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바이살라 데이터의 컬럼이름은 모두 일치하는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gangbyeon_vaisala_20230119_U_df = pd.read_csv(obs_data_list_vi[0])\n",
    "naebu_vaisala_20230119_U_df = pd.read_csv(obs_data_list_vi[1])\n",
    "dongbu_vaisala_20230119_U_df = pd.read_csv(obs_data_list_vi[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gangbyeon_vaisala_20230119_U_df['timestamp'] = pd.to_datetime(gangbyeon_vaisala_20230119_U_df['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 관측 데이터와 모델 데이터 병합 바이살라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract observational data information from file name\n",
    "def load_vi_data(file_name):\n",
    "    # file_name = obs_data_list[0] # select one file from file list\n",
    "    obs_df = pd.read_csv(file_name,usecols = ['timestamp','longitude','latitude','surface_temperature'])\n",
    "    obs_df['timestamp'] = pd.to_datetime(obs_df['timestamp'])\n",
    "    obs_df['day'] = obs_df['timestamp'].dt.day\n",
    "    obs_df['hour'] = obs_df['timestamp'].dt.hour\n",
    "    file_info = file_name.split(\"\\\\\")[-1].split(\"_\") # split the name for information\n",
    "    obs_site = file_info[0] #  get observation site information\n",
    "    sensor =  file_info[-3] \n",
    "    obs_road,obs_road_direction= file_info[-4], file_info[-1].split(\".\")[0]\n",
    "    year_month, day = file_info[-2][:6], file_info[-2][6:8] # get time imformation\n",
    "\n",
    "    return obs_df, obs_site, obs_road, obs_road_direction, year_month, day, sensor\n",
    "\n",
    "# extract observational data information from file name\n",
    "def load_lufft_data(file_name):\n",
    "    # file_name = obs_data_list[0] # select one file from file list\n",
    "    obs_df = pd.read_csv(file_name,usecols = ['Timestamp','longitude','latitude','Road temperature100 [°C] Cur'])\n",
    "    obs_df = obs_df.rename({'Road temperature100 [°C] Cur':'surface_temperature'},axis=1)\n",
    "    obs_df.columns = obs_df.columns.str.lower()\n",
    "    obs_df['timestamp'] = pd.to_datetime(obs_df['timestamp'])\n",
    "    obs_df['day'] = obs_df['timestamp'].dt.day\n",
    "    obs_df['hour'] = obs_df['timestamp'].dt.hour\n",
    "    file_info = file_name.split(\"\\\\\")[-1].split(\"_\") # split the name for information\n",
    "    obs_site = file_info[0] #  get observation site information\n",
    "    sensor =  file_info[-3] \n",
    "    obs_road,obs_road_direction= file_info[-4], file_info[-1].split(\".\")[0]\n",
    "    year_month, day = file_info[-2][:6], file_info[-2][6:8] # get time imformation\n",
    "\n",
    "    return obs_df, obs_site, obs_road, obs_road_direction, year_month, day, sensor\n",
    "\n",
    "def load_model_data(obs_site, year_month, day, obs_road, obs_road_direction):\n",
    "    model_df_all_site_list = []\n",
    "    model_sites = ['jr','mg','org','ss','yc']\n",
    "    for model_site in model_sites:\n",
    "        try:\n",
    "            model_data_list = [glob.glob(f\"../DATA/MODEL/{obs_site}/{model_site}/{year_month}/{day}/*csv\")[0],glob.glob(f\"../DATA/MODEL/{obs_site}/{model_site}/{year_month}/{int(day)-1}/*csv\")[0]]\n",
    "        except:\n",
    "            model_data_list = [glob.glob(f\"../DATA/MODEL/siheung/{model_site}/{year_month}/{day}/*csv\")[0],glob.glob(f\"../DATA/MODEL/siheung/{model_site}/{year_month}/{int(day)-1}/*csv\")[0]]\n",
    "        model_df_list = []\n",
    "        for model_file in model_data_list:\n",
    "            model_df_indiv =  pd.read_csv(model_file,usecols = ['date_time','update_time','lon','lat','road_name','direction','road_temp','p_hour'])\n",
    "            cond1 = model_df_indiv['road_name'] == obs_road\n",
    "            cond2 = model_df_indiv['direction'].str.startswith(obs_road_direction)\n",
    "            model_df_indiv = model_df_indiv[cond1 & cond2]\n",
    "            model_df_list.append(model_df_indiv)\n",
    "        model_df = pd.concat(model_df_list)\n",
    "\n",
    "        model_df['date_time'] = pd.to_datetime(model_df['date_time'])\n",
    "        model_df = model_df[model_df['date_time'].dt.day == int(day)]\n",
    "        model_df = model_df[~((model_df['date_time'].dt.hour == 15) & (model_df['p_hour']==24))]\n",
    "        model_df = model_df.rename({\"road_temp\":f\"{model_site}\"}, axis =1)\n",
    "\n",
    "        model_df_all_site_list.append(model_df)\n",
    "\n",
    "    model_data_df = model_df_all_site_list[0]\n",
    "    for df in model_df_all_site_list[1:]:\n",
    "        model_data_df = pd.merge(model_data_df, df, on=['lon', 'lat', 'date_time', 'update_time', 'p_hour', 'road_name', 'direction'])\n",
    "    model_data_df['date_time'] = pd.to_datetime(model_data_df['date_time'])\n",
    "    model_data_df['hour'] = model_data_df['date_time'].dt.hour\n",
    "    model_data_df['day'] = model_data_df['date_time'].dt.day\n",
    "\n",
    "    return model_data_df\n",
    "\n",
    "def perform_kdtree_matching_vi(obs_df, model_data_df):\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_df['longitude'], obs_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(observ_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in model_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(observ_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'lon': model_line[:, 0], 'lat': model_line[:, 1],\n",
    "                       'longitude': matched_lon, 'latitude': matched_lat})\n",
    "\n",
    "    total_df = pd.merge(df, obs_df, on=['longitude', 'latitude'])\n",
    "    total_df = pd.merge(total_df, model_data_df, on=['lon', 'lat','hour','day'])\n",
    "    \n",
    "    total_df = total_df.drop_duplicates()\n",
    "\n",
    "    return total_df\n",
    "\n",
    "def perform_kdtree_matching_lufft(obs_df, model_data_df):\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_df['longitude'], obs_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(model_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in observ_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(model_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'longitude': observ_line[:, 0], 'latitude': observ_line[:, 1],\n",
    "                       'lon': matched_lon, 'lat': matched_lat})\n",
    "\n",
    "    total_df = pd.merge(df, obs_df, on=['longitude', 'latitude'])\n",
    "    total_df = pd.merge(total_df, model_data_df, on=['lon', 'lat','hour','day'])\n",
    "    \n",
    "    total_df = total_df.drop_duplicates()\n",
    "\n",
    "    return total_df\n",
    "\n",
    "\n",
    "# 각 행에 대해 가장 가까운 값을 찾는 함수\n",
    "def find_closest(row):\n",
    "    temp = row['surface_temperature']\n",
    "    values = row[['jr', 'mg', 'org', 'ss', 'yc']].dropna() \n",
    "    closest_val = values.sub(temp).abs().idxmin()\n",
    "    return pd.Series([values[closest_val], closest_val])\n",
    "\n",
    "def main_process_vi(file):\n",
    "    obs_df, obs_site, obs_road, obs_road_direction, year_month, day, sensor = load_vi_data(file)\n",
    "    model_data_df = load_model_data(obs_site, year_month, day, obs_road, obs_road_direction)\n",
    "    df = perform_kdtree_matching_vi(obs_df,model_data_df)\n",
    "\n",
    "    # 새로운 컬럼을 추가하여 결과 저장\n",
    "    df_1 = df.reset_index()\n",
    "    df_1 = df_1.drop(['index'],axis = 1)\n",
    "    df_1[['closest_value', 'closest_column']] = df_1.apply(find_closest, axis=1)\n",
    "    df_1.to_csv(f\"../OUTPUT/{obs_site}_{obs_road}_{obs_road_direction}_{year_month}_{day}_{sensor}_concat.csv\", index=None)\n",
    "\n",
    "def main_process_lufft(file):\n",
    "    obs_df, obs_site, obs_road, obs_road_direction, year_month, day, sensor = load_lufft_data(file)\n",
    "    model_data_df = load_model_data(obs_site, year_month, day, obs_road, obs_road_direction)\n",
    "    df = perform_kdtree_matching_lufft(obs_df,model_data_df)\n",
    "\n",
    "    # 새로운 컬럼을 추가하여 결과 저장\n",
    "    df_1 = df.reset_index()\n",
    "    df_1 = df_1.drop(['index'],axis = 1)\n",
    "    df_1[['closest_value', 'closest_column']] = df_1.apply(find_closest, axis=1)\n",
    "    df_1.to_csv(f\"../OUTPUT/{obs_site}_{obs_road}_{obs_road_direction}_{year_month}_{day}_{sensor}_concat.csv\", index=None)\n",
    "\n",
    "\n",
    "obs_data_list = glob.glob(\"../DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/*csv\") # observational data file list\n",
    "obs_data_list_vi = glob.glob(\"../DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/*vai*csv\") # observational data file list\n",
    "obs_data_list_lufft = glob.glob(\"../DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/*lufft*csv\") # observational data file list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in obs_data_list_vi:\n",
    "    main_process_vi(i)\n",
    "\n",
    "for i in obs_data_list_lufft:\n",
    "    main_process_lufft(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/user/Desktop/모델검증/output\\seoul_dongbu_D_202301_26_lufft_concat.csv\n",
      "org RMSE: 3.802412704758773\tjr RMSE: 4.566446093405256\tss RMSE: 0.9559310086577861\tyc RMSE: 0.8912229052611237\tmg RMSE: 4.379045306558021\tclosest_value RMSE: 0.8908008170118288\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_dongbu_D_202301_27_lufft_concat.csv\n",
      "org RMSE: 2.509569535865475\tjr RMSE: 2.032480403011926\tss RMSE: 5.099827972368705\tyc RMSE: 5.035258856934394\tmg RMSE: 1.9843988981435567\tclosest_value RMSE: 0.7127833900026213\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_dongbu_U_202301_19_vaisala_concat.csv\n",
      "org RMSE: 1.7172232215597192\tjr RMSE: 1.934114923990452\tss RMSE: 4.2887247559282\tyc RMSE: 3.811792209419844\tmg RMSE: 3.3797400977365095\tclosest_value RMSE: 0.7882728567165652\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_gangbyeon_U_202301_19_vaisala_concat.csv\n",
      "org RMSE: 1.4231696896452413\tjr RMSE: 4.436327548398261\tss RMSE: 0.9463336079678354\tyc RMSE: 1.33121238944142\tmg RMSE: 7.195495881405455\tclosest_value RMSE: 0.7999712590874216\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_naebu_U_202301_19_vaisala_concat.csv\n",
      "org RMSE: 2.756501701712376\tjr RMSE: 5.736156519518744\tss RMSE: 2.622471272150131\tyc RMSE: 3.041939654795263\tmg RMSE: 8.221269438748761\tclosest_value RMSE: 2.107729214352348\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_olympic_D_202301_26_lufft_concat.csv\n",
      "org RMSE: 1.5292526479740995\tjr RMSE: 2.9596088119326067\tss RMSE: 2.786752679200256\tyc RMSE: 2.7732743929109374\tmg RMSE: 2.561205838140461\tclosest_value RMSE: 1.2241952963586678\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_olympic_D_202301_27_lufft_concat.csv\n",
      "org RMSE: 1.8684584395100612\tjr RMSE: 2.576624429716202\tss RMSE: 4.022667854816756\tyc RMSE: 3.9950320740092433\tmg RMSE: 2.330115498904307\tclosest_value RMSE: 0.7601093881248241\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_olympic_U_202301_17_lufft_concat.csv\n",
      "org RMSE: 2.0537100439893403\tjr RMSE: 2.817380148958728\tss RMSE: 2.980920351125232\tyc RMSE: 2.8627196241655457\tmg RMSE: 2.881654175593479\tclosest_value RMSE: 1.3359426413662785\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_olympic_U_202301_18_lufft_concat.csv\n",
      "org RMSE: 3.0483802707760552\tjr RMSE: 3.5122923684160243\tss RMSE: 2.2379953599845672\tyc RMSE: 2.177543511737356\tmg RMSE: 3.299627636290704\tclosest_value RMSE: 1.882085920557416\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_olympic_U_202301_19_lufft_concat.csv\n",
      "org RMSE: 3.432222218018714\tjr RMSE: 3.169822761480272\tss RMSE: 1.985680500291131\tyc RMSE: 1.7264281570878943\tmg RMSE: 3.891748704820147\tclosest_value RMSE: 1.659393415790982\t\n",
      "C:/Users/user/Desktop/모델검증/output\\seoul_seobu_D_202301_20_lufft_concat.csv\n",
      "org RMSE: 4.044137149765857\tjr RMSE: 3.1863175807584634\tss RMSE: 1.9427205768420532\tyc RMSE: 1.6896640192319343\tmg RMSE: 3.8511660181080725\tclosest_value RMSE: 1.6210381968088028\t\n",
      "C:/Users/user/Desktop/모델검증/output\\sihueng_SHR1_D_202301_20_lufft_concat.csv\n",
      "org RMSE: 6.438453727452887\tjr RMSE: 5.227183514306393\tss RMSE: 0.5848128683212868\tyc RMSE: 0.7646398854322634\tmg RMSE: 6.0846328683442685\tclosest_value RMSE: 0.5597972468219369\t\n",
      "C:/Users/user/Desktop/모델검증/output\\sihueng_SHR2_U_202301_20_lufft_concat.csv\n",
      "org RMSE: 4.499910397835102\tjr RMSE: 5.1825970136211925\tss RMSE: 0.6553626442584473\tyc RMSE: 0.7921623007994633\tmg RMSE: 6.0200103525407265\tclosest_value RMSE: 0.5822022507114769\t\n",
      "C:/Users/user/Desktop/모델검증/output\\sihueng_SHR3_D_202301_20_lufft_concat.csv\n",
      "org RMSE: 4.526171342425723\tjr RMSE: 5.3750825812629595\tss RMSE: 0.7010401564233449\tyc RMSE: 0.8862338062310918\tmg RMSE: 6.168757387759777\tclosest_value RMSE: 0.6652749521291578\t\n",
      "C:/Users/user/Desktop/모델검증/output\\sihueng_SHR4_U_202301_20_lufft_concat.csv\n",
      "org RMSE: 4.6041693018591765\tjr RMSE: 5.394111900552532\tss RMSE: 0.6379993268827742\tyc RMSE: 0.8654791405302152\tmg RMSE: 6.253854675049189\tclosest_value RMSE: 0.6195324374758509\t\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "df_list = glob.glob('C:/Users/user/Desktop/모델검증/output/S*.csv')\n",
    "# 두 개의 컬럼을 가진 데이터 프레임 df가 있다고 가정합니다.\n",
    "# 'actual'과 'predicted'라는 두 개의 컬럼이 있다고 가정합니다.\n",
    "for j in df_list:\n",
    "    df = pd.read_csv(j)\n",
    "    # 실제값과 예측값을 가져옵니다.\n",
    "    print(j)\n",
    "    for i in ['org', 'jr',  'ss', 'yc','mg','closest_value']:\n",
    "        actual = df['surface_temperature']\n",
    "        predicted = df[i]\n",
    "\n",
    "        # MSE(Mean Squared Error)를 계산합니다.\n",
    "        mse = mean_squared_error(actual, predicted)\n",
    "\n",
    "        # MSE의 제곱근을 계산하여 RMSE를 얻습니다.\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        print(f\"{i} RMSE:\", rmse, end = \"\\t\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
