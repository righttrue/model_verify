{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "# import cartopy.crs as ccrs\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일별 로드 & 특이사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naebu 20230119 U\n",
      "[19] [16 17]\n",
      "gangbyeon 20230119 U\n",
      "dongbu 20230126 D\n",
      "dongbu 20230127 D\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_vaisala_20230119_U'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 114\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m#===================================================================\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m#============================================================================================================================================================\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m#seoul_3_dongbu_lufft_20230127_D.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_vaisala_20230119_U\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m obs_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m obs_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m obs_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    117\u001b[0m file_info \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\demo\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\demo\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\demo\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\demo\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\demo\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_vaisala_20230119_U'"
     ]
    }
   ],
   "source": [
    "#============================================================================================================================================================\n",
    "#seoul_2_naebu_vaisala_20230119_U\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_2_naebu_vaisala_20230119_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "print(data_obs_test[\"day\"].unique(),data_obs_test[\"hour\"].unique())\n",
    "#============================================================================================================================================================\n",
    "#  seoul_1_gangbyeon_vaisala_20230119_U\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_1_gangbyeon_vaisala_20230119_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "\n",
    "\n",
    "# 강병 도로 특이 사항\n",
    "# cond1 = model_road['lon'] >= 126.9061243663102\n",
    "# cond2 = model_road['lat'] <= 37.54867362377485\n",
    "# cond3 = model_road['lon'] <= 126.91043059457456\n",
    "# cond4 = model_road['lat'] >= 37.545676738065886\n",
    "\n",
    "# model_road = model_road[~(cond1 & cond2 & cond3 & cond4)]\n",
    "#============================================================================================================================================================\n",
    "#seoul_3_dongbu_lufft_20230126_D\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_lufft_20230126_D.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "#===================================================================\n",
    "\n",
    "\n",
    "#============================================================================================================================================================\n",
    "#seoul_3_dongbu_lufft_20230127_D.\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_lufft_20230127_D.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "\n",
    "\n",
    "# 동부 도로 특이 사항\n",
    "cond1 = model_road['lon'] >= 127.0528247\n",
    "cond2 = model_road['lat'] >= 37.6836121\n",
    "\n",
    "\n",
    "cond3 = model_road['lon'] >=127.0308726\n",
    "cond4 = model_road['lon'] <= 127.0339521\n",
    "\n",
    "cond5 = model_road['lat'] <= 37.5435276\n",
    "cond6 = model_road['lat'] >= 37.5414698\n",
    "\n",
    "model_road = model_road[~(cond1 & cond2)]\n",
    "model_road = model_road[~(cond3 & cond4 & cond5 & cond6)]\n",
    "#===================================================================\n",
    "\n",
    "#============================================================================================================================================================\n",
    "#seoul_3_dongbu_lufft_20230127_D.\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_vaisala_20230119_U\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "#===================================================================\n",
    "\n",
    "\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_5_olympic_lufft_20230119_U.csv\"\n",
    "date_set = 19\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "cond1 = data_obs_test['longitude'] >=126.805483\n",
    "cond2 = data_obs_test['latitude'] <= 37.5911\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongbu 20230126 D\n",
      "[26] [11]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#seoul_2_naebu_vaisala_20230119_U\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_lufft_20230126_D.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "print(data_obs_test[\"day\"].unique(),data_obs_test[\"hour\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 바이살라 _ 중복 해결할 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongbu 20230119 U\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23152\\4050416020.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  model_road = model_road[~(cond3 & cond4 & cond5 & cond6)]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23152\\4050416020.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  model_road = model_road[~(cond3 & cond4 & cond5 & cond6)]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23152\\4050416020.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  model_road = model_road[~(cond3 & cond4 & cond5 & cond6)]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23152\\4050416020.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  model_road = model_road[~(cond3 & cond4 & cond5 & cond6)]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23152\\4050416020.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  model_road = model_road[~(cond3 & cond4 & cond5 & cond6)]\n"
     ]
    }
   ],
   "source": [
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_vaisala_20230119_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "\n",
    "\n",
    "            \n",
    "# 찾은 CSV 파일들을 출력\n",
    "sites = ['jr','mg','org','ss','yc']\n",
    "for site in sites:\n",
    "    jr_model_file = f\"C:/Users/user/Desktop/모델검증/DATA/MODEL/seoul/{site}/202301/18/KMA_HUFS_ROAD-P_seoul_20230118150000.csv\"\n",
    "    model_road = pd.read_csv(jr_model_file)\n",
    "    cond1 = model_road['road_name'] == road_name\n",
    "    cond2 = model_road['direction'].str.startswith(road_dir_1)\n",
    "    model_road = model_road[cond1&cond2]\n",
    "    #site_list.append(model_road)\n",
    "\n",
    "    model_road['date_time'] = pd.to_datetime(model_road['date_time'])\n",
    "    model_road['hour'] = model_road['date_time'].dt.hour\n",
    "    model_road['day'] = model_road['date_time'].dt.day\n",
    "    cond1 = model_road['lon'] >= 127.0528247\n",
    "    cond2 = model_road['lat'] >= 37.6836121\n",
    "\n",
    "\n",
    "    cond3 = model_road['lon'] >=127.0308726\n",
    "    cond4 = model_road['lon'] <= 127.0339521\n",
    "\n",
    "    cond5 = model_road['lat'] <= 37.5435276\n",
    "    cond6 = model_road['lat'] >= 37.5414698\n",
    "\n",
    "    model_road = model_road[~(cond1 & cond2)]\n",
    "    model_road = model_road[~(cond3 & cond4 & cond5 & cond6)]\n",
    "    model_1 = model_road\n",
    "    \n",
    "\n",
    "    model_data_df = model_1.copy() # 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\n",
    "    obs_date_df = data_obs_test.copy() # 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\n",
    "\n",
    "    #KDTree 를 통한 근접 점 찾기\n",
    "    road_df = pd.DataFrame()\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_date_df['longitude'], obs_date_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(observ_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in model_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(observ_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'lon': model_line[:, 0], 'lat': model_line[:, 1],\n",
    "                        'longitude': matched_lon, 'latitude': matched_lat})\n",
    "\n",
    "    model_date_2 = model_data_df.copy()\n",
    "    \n",
    "    total_df = pd.merge(df,data_obs_test,on=['longitude','latitude'])\n",
    "    #print(total_df)\n",
    "\n",
    "    total_df = pd.merge(total_df,model_date_2,on=['lon','lat','hour','day'])\n",
    "    total_df = total_df.drop_duplicates()\n",
    "    road_df = pd.concat([road_df,total_df])\n",
    "\n",
    "    road_df.to_csv(f\"C:/Users/user/Desktop/모델검증/DATA/{road_name}{date}{road_dir_1}_{site}.csv\", index=False)\n",
    "    del road_df, model_road"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 루프트 _ 중복 문제 해결 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongbu 20230119 U\n",
      "[19] [12 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23152\\1477104878.py:32: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data_obs_test = data_obs_test[~(cond3 & cond4 & cond5 & cond6)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 57\u001b[0m\n\u001b[0;32m     52\u001b[0m model_road[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model_road[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 동부 도로 특이 사항\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m model_data_df \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m# 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\u001b[39;00m\n\u001b[0;32m     58\u001b[0m obs_date_df \u001b[38;5;241m=\u001b[39m data_obs_test\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m# 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#KDTree 를 통한 근접 점 찾기\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_1' is not defined"
     ]
    }
   ],
   "source": [
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_vaisala_20230119_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "cond1 = data_obs_test['longitude'] >= 127.0308590093344\n",
    "cond2 = data_obs_test['latitude'] <= 37.543546568354365\n",
    "\n",
    "cond11 = data_obs_test['longitude'] <= 127.06588902545067\n",
    "cond21 = data_obs_test['latitude'] >= 37.531453489606754\n",
    "\n",
    "cond3 = data_obs_test['longitude'] >=127.0308726\n",
    "cond4 = data_obs_test['longitude'] <= 127.0339521\n",
    "\n",
    "cond5 = data_obs_test['latitude'] <= 37.5435276\n",
    "cond6 = data_obs_test['latitude'] >= 37.5414698\n",
    "\n",
    "data_obs_test = data_obs_test[~(cond1 & cond2 & cond11 & cond21)]\n",
    "data_obs_test = data_obs_test[~(cond3 & cond4 & cond5 & cond6)]\n",
    "data_obs_test = data_obs_test\n",
    "    \n",
    "\n",
    "print(data_obs_test[\"day\"].unique(),data_obs_test[\"hour\"].unique())\n",
    "#관측 자료 특이사항 제거\n",
    "\n",
    "            \n",
    "# 찾은 CSV 파일들을 출력\n",
    "sites = ['jr','mg','org','ss','yc']\n",
    "for site in sites:\n",
    "    jr_model_file = f\"C:/Users/user/Desktop/모델검증/DATA/MODEL/seoul/{site}/202301/18/KMA_HUFS_ROAD-P_seoul_20230118150000.csv\"\n",
    "    model_road = pd.read_csv(jr_model_file)\n",
    "    cond1 = model_road['road_name'] == road_name\n",
    "    cond2 = model_road['direction'].str.startswith(road_dir_1)\n",
    "    model_road = model_road[cond1&cond2]\n",
    "    #site_list.append(model_road)\n",
    "\n",
    "    model_road['date_time'] = pd.to_datetime(model_road['date_time'])\n",
    "    model_road['hour'] = model_road['date_time'].dt.hour\n",
    "    model_road['day'] = model_road['date_time'].dt.day\n",
    "    \n",
    "    # 동부 도로 특이 사항\n",
    "    \n",
    "\n",
    "    model_data_df = model_1.copy() # 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\n",
    "    obs_date_df = data_obs_test.copy() # 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\n",
    "\n",
    "    #KDTree 를 통한 근접 점 찾기\n",
    "    road_df = pd.DataFrame()\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_date_df['longitude'], obs_date_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(model_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in observ_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(model_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'longitude': observ_line[:, 0], 'latitude': observ_line[:, 1],\n",
    "                        'lon': matched_lon, 'lat': matched_lat})\n",
    "\n",
    "    model_date_2 = model_data_df.copy()\n",
    "    \n",
    "    total_df = pd.merge(df,data_obs_test,on=['longitude','latitude'])\n",
    "    #print(total_df)\n",
    "\n",
    "    total_df = pd.merge(total_df,model_date_2,on=['lon','lat','hour','day'])\n",
    "    total_df = total_df.drop_duplicates()\n",
    "    road_df = pd.concat([road_df,total_df])\n",
    "    road_df = road_df.drop_duplicates(subset=[\"lon\",\"lat\"])\n",
    "    road_df.to_csv(f\"C:/Users/user/Desktop/모델검증/DATA/{road_name}{date}{road_dir_1}_{site}.csv\", index=False)\n",
    "    del road_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE 계산 _ 폴더별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seobu20230120D_jr.csv 3.2020765577346437\n",
      "jr 3.2020765577346437\n",
      "seobu20230120D_mg.csv 3.866958824738542\n",
      "mg 3.866958824738542\n",
      "seobu20230120D_org.csv 4.070856791474281\n",
      "org 4.070856791474281\n",
      "seobu20230120D_ss.csv 1.9261373363001337\n",
      "ss 1.9261373363001337\n",
      "seobu20230120D_yc.csv 1.673166860645253\n",
      "yc 1.673166860645253\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a list of CSV file paths named csv_files\n",
    "def cal_rmse_df(site):\n",
    "    csv_files = glob.glob('C:/Users/user/Desktop/모델검증/DATA/veri/seobu/' + '*.csv')\n",
    "    \n",
    "    df_list = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)  # Use csv_file instead of csv_files\n",
    "        if site in csv_file:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # Check if either 'road temperature100 [°c] cur' or 'surface_temperature' is present\n",
    "            if 'road temperature100 [°c] cur' in df.columns:\n",
    "                # Rename 'road temperature100 [°c] cur' to 'surface_temperature'\n",
    "                df.rename(columns={'road temperature100 [°c] cur': 'surface_temperature'}, inplace=True)\n",
    "            elif 'surface_temperature' in df.columns:\n",
    "                # Do nothing, as the desired column name is already present\n",
    "                pass\n",
    "            else:\n",
    "                # Handle the case when neither column is present if needed\n",
    "                \n",
    "                pass\n",
    "            df_mse = mean_squared_error(df['road_temp'], df['surface_temperature'])\n",
    "            df_rmse = np.sqrt(df_mse)\n",
    "            print(csv_file.split(\"\\\\\")[-1],end=\" \")\n",
    "            print(df_rmse)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenate the list of dataframes into a single dataframe\n",
    "    dfs = pd.concat(df_list, ignore_index=True)  # ignore_index=True resets the index\n",
    "    mse = mean_squared_error(dfs['road_temp'], dfs['surface_temperature'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(site,rmse)\n",
    "    \n",
    "    \n",
    "models  = [\"jr\",\"mg\",\"org\",\"ss\",\"yc\"]\n",
    "for model in models:\n",
    "    cal_rmse_df(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongbu20230119U_jr.csv 2.5013532687404085\n",
      "jr 2.5013532687404085\n",
      "dongbu20230119U_mg.csv 4.7661503101240426\n",
      "mg 4.7661503101240426\n",
      "dongbu20230119U_org.csv 1.5409361913253692\n",
      "org 1.5409361913253692\n",
      "dongbu20230119U_ss.csv 2.672316237016886\n",
      "ss 2.672316237016886\n",
      "dongbu20230119U_yc.csv 2.1607386641944175\n",
      "yc 2.1607386641944175\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a list of CSV file paths named csv_files\n",
    "def cal_rmse_df(site):\n",
    "    csv_files = glob.glob('C:/Users/user/Desktop/모델검증/DATA/test/' + '*.csv')\n",
    "    \n",
    "    df_list = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)  # Use csv_file instead of csv_files\n",
    "        if site in csv_file:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df = df[df['hour'] == 13]\n",
    "            # Check if either 'road temperature100 [°c] cur' or 'surface_temperature' is present\n",
    "            if 'road temperature100 [°c] cur' in df.columns:\n",
    "                # Rename 'road temperature100 [°c] cur' to 'surface_temperature'\n",
    "                df.rename(columns={'road temperature100 [°c] cur': 'surface_temperature'}, inplace=True)\n",
    "            elif 'surface_temperature' in df.columns:\n",
    "                # Do nothing, as the desired column name is already present\n",
    "                pass\n",
    "            else:\n",
    "                # Handle the case when neither column is present if needed\n",
    "                \n",
    "                pass\n",
    "            df_mse = mean_squared_error(df['road_temp'], df['surface_temperature'])\n",
    "            df_rmse = np.sqrt(df_mse)\n",
    "            print(csv_file.split(\"\\\\\")[-1],end=\" \")\n",
    "            print(df_rmse)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenate the list of dataframes into a single dataframe\n",
    "    dfs = pd.concat(df_list, ignore_index=True)  # ignore_index=True resets the index\n",
    "    mse = mean_squared_error(dfs['road_temp'], dfs['surface_temperature'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(site,rmse)\n",
    "    \n",
    "    \n",
    "models  = [\"jr\",\"mg\",\"org\",\"ss\",\"yc\"]\n",
    "for model in models:\n",
    "    cal_rmse_df(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 올림픽 RMSE 계산 재실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olympic 20230119 U\n",
      "[20 19] [ 0 23]\n"
     ]
    }
   ],
   "source": [
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_5_olympic_lufft_20230119_U.csv\"\n",
    "date_set = 19\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "cond1 = data_obs_test['longitude'] >=126.805483\n",
    "cond2 = data_obs_test['latitude'] <= 37.5911\n",
    "\n",
    "\n",
    "data_obs_test = data_obs_test[cond1 & cond2]\n",
    "data_obs_test = data_obs_test\n",
    "    \n",
    "\n",
    "print(data_obs_test[\"day\"].unique(),data_obs_test[\"hour\"].unique())\n",
    "#관측 자료 특이사항 제거\n",
    "\n",
    "            \n",
    "# 찾은 CSV 파일들을 출력\n",
    "sites = ['jr','mg','org','ss','yc']\n",
    "for site in sites:\n",
    "    jr_model_file = f\"C:/Users/user/Desktop/모델검증/DATA/MODEL/seoul/{site}/202301/{date_set}/KMA_HUFS_ROAD-P_seoul_202301{date_set}150000.csv\"\n",
    "    model_road = pd.read_csv(jr_model_file)\n",
    "    cond1 = model_road['road_name'] == road_name\n",
    "    cond2 = model_road['direction'].str.startswith(road_dir_1)\n",
    "    model_road = model_road[cond1&cond2]\n",
    "    #site_list.append(model_road)\n",
    "\n",
    "    model_road['date_time'] = pd.to_datetime(model_road['date_time'])\n",
    "    model_road['hour'] = model_road['date_time'].dt.hour\n",
    "    model_road['day'] = model_road['date_time'].dt.day\n",
    "    #model_road = model_road\n",
    "    # 동부 도로 특이 사항\n",
    "    \n",
    "\n",
    "    model_data_df = model_road.copy() # 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\n",
    "    obs_date_df = data_obs_test.copy() # 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\n",
    "\n",
    "    #KDTree 를 통한 근접 점 찾기\n",
    "    road_df = pd.DataFrame()\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_date_df['longitude'], obs_date_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(model_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in observ_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(model_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'longitude': observ_line[:, 0], 'latitude': observ_line[:, 1],\n",
    "                        'lon': matched_lon, 'lat': matched_lat})\n",
    "\n",
    "    model_date_2 = model_data_df.copy()\n",
    "    \n",
    "    total_df = pd.merge(df,data_obs_test,on=['longitude','latitude'])\n",
    "    #print(total_df)\n",
    "\n",
    "    total_df = pd.merge(total_df,model_date_2,on=['lon','lat','hour','day'])\n",
    "    total_df = total_df.drop_duplicates()\n",
    "    road_df = pd.concat([road_df,total_df])\n",
    "    road_df = road_df.drop_duplicates(subset=[\"lon\",\"lat\"])\n",
    "    road_df.to_csv(f\"C:/Users/user/Desktop/모델검증/DATA/test/{road_name}{date}{road_dir_1}_{site}.csv\", index=False)\n",
    "    del road_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_5_olympic_lufft_20230226_D.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>road temperature100 [°c] cur</th>\n",
       "      <th>amb. temperature110 [°c] cur</th>\n",
       "      <th>dewpoint temperature120 [°c] cur</th>\n",
       "      <th>rel. humidity o.r.200 [%] cur</th>\n",
       "      <th>rel. humidity210 [%] cur</th>\n",
       "      <th>waterfilm height610 [mm] cur</th>\n",
       "      <th>wfh on surface611 [mm] cur</th>\n",
       "      <th>snow height612 [mm] cur</th>\n",
       "      <th>ice percentage800 [%] cur</th>\n",
       "      <th>friction820 [n/a] cur</th>\n",
       "      <th>road condition900 [logic] cur</th>\n",
       "      <th>image</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-26 10:28</td>\n",
       "      <td>-2.2160</td>\n",
       "      <td>-5.5129</td>\n",
       "      <td>-6.8308</td>\n",
       "      <td>70.4341</td>\n",
       "      <td>83.3915</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_0126_102832-37.592833-126.801033.jpg</td>\n",
       "      <td>37.592833</td>\n",
       "      <td>126.801033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-26 10:28</td>\n",
       "      <td>-2.2702</td>\n",
       "      <td>-5.5129</td>\n",
       "      <td>-6.8308</td>\n",
       "      <td>70.4341</td>\n",
       "      <td>83.3915</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_0126_102832-37.592833-126.801033.jpg</td>\n",
       "      <td>37.592833</td>\n",
       "      <td>126.801033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-26 10:28</td>\n",
       "      <td>-2.3418</td>\n",
       "      <td>-5.5129</td>\n",
       "      <td>-6.8308</td>\n",
       "      <td>70.4341</td>\n",
       "      <td>83.3915</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8173</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_0126_102832-37.592833-126.801033.jpg</td>\n",
       "      <td>37.592833</td>\n",
       "      <td>126.801033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-26 10:28</td>\n",
       "      <td>-2.4569</td>\n",
       "      <td>-5.5129</td>\n",
       "      <td>-6.8308</td>\n",
       "      <td>70.4341</td>\n",
       "      <td>83.3915</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8170</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_0126_102832-37.592833-126.801033.jpg</td>\n",
       "      <td>37.592833</td>\n",
       "      <td>126.801033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-26 10:28</td>\n",
       "      <td>-2.5545</td>\n",
       "      <td>-5.5129</td>\n",
       "      <td>-6.8308</td>\n",
       "      <td>70.4341</td>\n",
       "      <td>83.3915</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>0</td>\n",
       "      <td>2023_0126_102832-37.592833-126.801033.jpg</td>\n",
       "      <td>37.592833</td>\n",
       "      <td>126.801033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17220</th>\n",
       "      <td>2023-01-26 11:09</td>\n",
       "      <td>-2.6938</td>\n",
       "      <td>-5.9437</td>\n",
       "      <td>-7.2113</td>\n",
       "      <td>70.8757</td>\n",
       "      <td>83.6237</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.7336</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>3</td>\n",
       "      <td>2023_0126_110948-37.521883-127.061383.jpg</td>\n",
       "      <td>37.521883</td>\n",
       "      <td>127.061383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17221</th>\n",
       "      <td>2023-01-26 11:09</td>\n",
       "      <td>-2.7394</td>\n",
       "      <td>-5.9437</td>\n",
       "      <td>-7.2113</td>\n",
       "      <td>70.8757</td>\n",
       "      <td>83.6237</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.6482</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>3</td>\n",
       "      <td>2023_0126_110948-37.521883-127.061383.jpg</td>\n",
       "      <td>37.521883</td>\n",
       "      <td>127.061383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17222</th>\n",
       "      <td>2023-01-26 11:09</td>\n",
       "      <td>-2.7567</td>\n",
       "      <td>-5.9437</td>\n",
       "      <td>-7.2113</td>\n",
       "      <td>70.8757</td>\n",
       "      <td>83.6237</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.6685</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>3</td>\n",
       "      <td>2023_0126_110948-37.521883-127.061383.jpg</td>\n",
       "      <td>37.521883</td>\n",
       "      <td>127.061383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17223</th>\n",
       "      <td>2023-01-26 11:09</td>\n",
       "      <td>-2.7611</td>\n",
       "      <td>-5.9437</td>\n",
       "      <td>-7.2113</td>\n",
       "      <td>70.8757</td>\n",
       "      <td>83.6237</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.7789</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>3</td>\n",
       "      <td>2023_0126_110948-37.521883-127.061383.jpg</td>\n",
       "      <td>37.521883</td>\n",
       "      <td>127.061383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17224</th>\n",
       "      <td>2023-01-26 11:09</td>\n",
       "      <td>-2.7719</td>\n",
       "      <td>-5.9437</td>\n",
       "      <td>-7.2113</td>\n",
       "      <td>70.8757</td>\n",
       "      <td>83.6237</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.9557</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>3</td>\n",
       "      <td>2023_0126_110949-37.521783-127.061450.jpg</td>\n",
       "      <td>37.521783</td>\n",
       "      <td>127.061450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17225 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp  road temperature100 [°c] cur  \\\n",
       "0      2023-01-26 10:28                       -2.2160   \n",
       "1      2023-01-26 10:28                       -2.2702   \n",
       "2      2023-01-26 10:28                       -2.3418   \n",
       "3      2023-01-26 10:28                       -2.4569   \n",
       "4      2023-01-26 10:28                       -2.5545   \n",
       "...                 ...                           ...   \n",
       "17220  2023-01-26 11:09                       -2.6938   \n",
       "17221  2023-01-26 11:09                       -2.7394   \n",
       "17222  2023-01-26 11:09                       -2.7567   \n",
       "17223  2023-01-26 11:09                       -2.7611   \n",
       "17224  2023-01-26 11:09                       -2.7719   \n",
       "\n",
       "       amb. temperature110 [°c] cur  dewpoint temperature120 [°c] cur  \\\n",
       "0                           -5.5129                           -6.8308   \n",
       "1                           -5.5129                           -6.8308   \n",
       "2                           -5.5129                           -6.8308   \n",
       "3                           -5.5129                           -6.8308   \n",
       "4                           -5.5129                           -6.8308   \n",
       "...                             ...                               ...   \n",
       "17220                       -5.9437                           -7.2113   \n",
       "17221                       -5.9437                           -7.2113   \n",
       "17222                       -5.9437                           -7.2113   \n",
       "17223                       -5.9437                           -7.2113   \n",
       "17224                       -5.9437                           -7.2113   \n",
       "\n",
       "       rel. humidity o.r.200 [%] cur  rel. humidity210 [%] cur  \\\n",
       "0                            70.4341                   83.3915   \n",
       "1                            70.4341                   83.3915   \n",
       "2                            70.4341                   83.3915   \n",
       "3                            70.4341                   83.3915   \n",
       "4                            70.4341                   83.3915   \n",
       "...                              ...                       ...   \n",
       "17220                        70.8757                   83.6237   \n",
       "17221                        70.8757                   83.6237   \n",
       "17222                        70.8757                   83.6237   \n",
       "17223                        70.8757                   83.6237   \n",
       "17224                        70.8757                   83.6237   \n",
       "\n",
       "       waterfilm height610 [mm] cur  wfh on surface611 [mm] cur  \\\n",
       "0                            0.0044                      0.0038   \n",
       "1                            0.0052                      0.0044   \n",
       "2                            0.0060                      0.0050   \n",
       "3                            0.0069                      0.0056   \n",
       "4                            0.0072                      0.0059   \n",
       "...                             ...                         ...   \n",
       "17220                        0.0782                      0.0000   \n",
       "17221                        0.0777                      0.0000   \n",
       "17222                        0.0778                      0.0000   \n",
       "17223                        0.0785                      0.0000   \n",
       "17224                        0.0797                      0.0000   \n",
       "\n",
       "       snow height612 [mm] cur  ice percentage800 [%] cur  \\\n",
       "0                       0.0000                        0.0   \n",
       "1                       0.0000                        0.0   \n",
       "2                       0.0000                        0.0   \n",
       "3                       0.0000                        0.0   \n",
       "4                       0.0000                        0.0   \n",
       "...                        ...                        ...   \n",
       "17220                  11.7336                      100.0   \n",
       "17221                  11.6482                      100.0   \n",
       "17222                  11.6685                      100.0   \n",
       "17223                  11.7789                      100.0   \n",
       "17224                  11.9557                      100.0   \n",
       "\n",
       "       friction820 [n/a] cur  road condition900 [logic] cur  \\\n",
       "0                     0.8180                              0   \n",
       "1                     0.8176                              0   \n",
       "2                     0.8173                              0   \n",
       "3                     0.8170                              0   \n",
       "4                     0.8169                              0   \n",
       "...                      ...                            ...   \n",
       "17220                 0.6823                              3   \n",
       "17221                 0.6824                              3   \n",
       "17222                 0.6821                              3   \n",
       "17223                 0.6813                              3   \n",
       "17224                 0.6800                              3   \n",
       "\n",
       "                                           image   latitude   longitude  \n",
       "0      2023_0126_102832-37.592833-126.801033.jpg  37.592833  126.801033  \n",
       "1      2023_0126_102832-37.592833-126.801033.jpg  37.592833  126.801033  \n",
       "2      2023_0126_102832-37.592833-126.801033.jpg  37.592833  126.801033  \n",
       "3      2023_0126_102832-37.592833-126.801033.jpg  37.592833  126.801033  \n",
       "4      2023_0126_102832-37.592833-126.801033.jpg  37.592833  126.801033  \n",
       "...                                          ...        ...         ...  \n",
       "17220  2023_0126_110948-37.521883-127.061383.jpg  37.521883  127.061383  \n",
       "17221  2023_0126_110948-37.521883-127.061383.jpg  37.521883  127.061383  \n",
       "17222  2023_0126_110948-37.521883-127.061383.jpg  37.521883  127.061383  \n",
       "17223  2023_0126_110948-37.521883-127.061383.jpg  37.521883  127.061383  \n",
       "17224  2023_0126_110949-37.521783-127.061450.jpg  37.521783  127.061450  \n",
       "\n",
       "[17225 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 21) (3152811263.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour'\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_file(self, file_loaction,file_type.road_name):\n",
    "    df = pd.read_csv(file_loaction,low_memory=False)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    if file_type == 'obs':\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "        df[\"year\"] = df[\"timestamp\"].dt.year\n",
    "        df[\"month\"] = df[\"timestamp\"].dt.month\n",
    "        df[\"day\"] = df[\"timestamp\"].dt.day\n",
    "        df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    \n",
    "    else:\n",
    "        cond1 = df['road_name'] == road_name\n",
    "        cond2 = df['direction'].str.startswith(road_dir_1)\n",
    "        df = df[cond1&cond2]\n",
    "        df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "        df['hour'] = df['date_time'].dt.hour\n",
    "        df['day'] = df['date_time'].dt.day\n",
    "    print(file_loaction,df[\"day\"].unique(),df[\"hour\"].unique())\n",
    "    return df\n",
    "\n",
    "\n",
    "def file_info(self, df):\n",
    "    file_info = file.split('_')\n",
    "    road_name = file_info[-4]\n",
    "    date = file_info[-2]\n",
    "    road_dir_1 = file_info[-1]\n",
    "    road_dir_1 = road_dir_1.split('.')[0]\n",
    "    date = file_info[-2]\n",
    "    \n",
    "    return file_info, road_name, road_dir_1, date\n",
    "\n",
    "def road_feature(self,data_obs_test, road_name):\n",
    "    if road_name == 'dongbu':\n",
    "        cond1 = (data_obs_test['longitude'] >= 127.0308590093344) & (data_obs_test['latitude'] <= 37.543546568354365)\n",
    "        cond2 = (data_obs_test['longitude'] <= 127.06588902545067) & (data_obs_test['latitude'] >= 37.531453489606754)\n",
    "        cond3 = (data_obs_test['longitude'] >= 127.0308726) & (data_obs_test['longitude'] <= 127.0339521)\n",
    "        cond4 = (data_obs_test['latitude'] <= 37.5435276) & (data_obs_test['latitude'] >= 37.5414698)\n",
    "\n",
    "        data_obs_test = data_obs_test[~((cond1 & cond2) | (cond3 & cond4))]\n",
    "    elif road_name==\"oly\":\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "    return data_obs_test\n",
    "\n",
    "            \n",
    "\n",
    "def matching_road(obs_date_df,model_data_df):\n",
    "    #KDTree 를 통한 근접 점 찾기\n",
    "    road_df = pd.DataFrame()\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_date_df['longitude'], obs_date_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(model_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in observ_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(model_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'longitude': observ_line[:, 0], 'latitude': observ_line[:, 1],\n",
    "                        'lon': matched_lon, 'lat': matched_lat})\n",
    "\n",
    "    model_date_2 = model_data_df.copy()\n",
    "\n",
    "    total_df = pd.merge(df,data_obs_test,on=['longitude','latitude'])\n",
    "    #print(total_df)\n",
    "\n",
    "    total_df = pd.merge(total_df,model_date_2,on=['lon','lat','hour','day'])\n",
    "    total_df = total_df.drop_duplicates()\n",
    "    road_df = pd.concat([road_df,total_df])\n",
    "    road_df = road_df.drop_duplicates(subset=[\"lon\",\"lat\"])\n",
    "    return road_df\n",
    "\n",
    "# 찾은 CSV 파일들을 출력\n",
    "sites = ['jr','mg','org','ss','yc']\n",
    "for site in sites:\n",
    "    jr_model_file = f\"C:/Users/user/Desktop/모델검증/DATA/MODEL/seoul/{site}/202301/18/KMA_HUFS_ROAD-P_seoul_20230118150000.csv\"\n",
    "    model_road = pd.read_csv(jr_model_file)\n",
    "    cond1 = model_road['road_name'] == road_name\n",
    "    cond2 = model_road['direction'].str.startswith(road_dir_1)\n",
    "    model_road = model_road[cond1&cond2]\n",
    "    #site_list.append(model_road)\n",
    "\n",
    "    model_road['date_time'] = pd.to_datetime(model_road['date_time'])\n",
    "    model_road['hour'] = model_road['date_time'].dt.hour\n",
    "    model_road['day'] = model_road['date_time'].dt.day\n",
    "    \n",
    "    # 동부 도로 특이 사항\n",
    "    \n",
    "\n",
    "    model_data_df = model_1.copy() # 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\n",
    "    obs_date_df = data_obs_test.copy() # 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\n",
    "    road_df = matching_road(obs_date_df,model_data_df)\n",
    "    road_df.to_csv(f\"C:/Users/user/Desktop/모델검증/DATA/{road_name}{date}{road_dir_1}_{site}.csv\", index=False)\n",
    "    del road_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시흥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR4 20230120 U\n",
      "[20] [1]\n"
     ]
    }
   ],
   "source": [
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/sihueng_SHR4_lufft_20230120_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "# cond1 = data_obs_test['longitude'] >= 127.0308590093344\n",
    "# cond2 = data_obs_test['latitude'] <= 37.543546568354365\n",
    "\n",
    "# cond11 = data_obs_test['longitude'] <= 127.06588902545067\n",
    "# cond21 = data_obs_test['latitude'] >= 37.531453489606754\n",
    "\n",
    "# cond3 = data_obs_test['longitude'] >=127.0308726\n",
    "# cond4 = data_obs_test['longitude'] <= 127.0339521\n",
    "\n",
    "# cond5 = data_obs_test['latitude'] <= 37.5435276\n",
    "# cond6 = data_obs_test['latitude'] >= 37.5414698\n",
    "\n",
    "# data_obs_test = data_obs_test[~(cond1 & cond2 & cond11 & cond21)]\n",
    "# data_obs_test = data_obs_test[~(cond3 & cond4 & cond5 & cond6)]\n",
    "data_obs_test = data_obs_test\n",
    "    \n",
    "\n",
    "print(data_obs_test[\"day\"].unique(),data_obs_test[\"hour\"].unique())\n",
    "#관측 자료 특이사항 제거\n",
    "\n",
    "            \n",
    "# 찾은 CSV 파일들을 출력\n",
    "sites = ['jr','mg','org','ss','yc']\n",
    "for site in sites:\n",
    "    jr_model_file = f\"C:/Users/user/Desktop/모델검증/DATA/MODEL/siheung/{site}/202301/19/KMA_HUFS_ROAD-P_siheung_20230119150000.csv\"\n",
    "    model_road = pd.read_csv(jr_model_file)\n",
    "    cond1 = model_road['road_name'] == road_name\n",
    "    cond2 = model_road['direction'].str.startswith(road_dir_1)\n",
    "    model_road = model_road[cond1&cond2]\n",
    "    #site_list.append(model_road)\n",
    "\n",
    "    model_road['date_time'] = pd.to_datetime(model_road['date_time'])\n",
    "    model_road['hour'] = model_road['date_time'].dt.hour\n",
    "    model_road['day'] = model_road['date_time'].dt.day\n",
    "    \n",
    "    # 동부 도로 특이 사항\n",
    "    \n",
    "\n",
    "    model_data_df = model_road.copy() # 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\n",
    "    obs_date_df = data_obs_test.copy() # 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\n",
    "\n",
    "    #KDTree 를 통한 근접 점 찾기\n",
    "    road_df = pd.DataFrame()\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_date_df['longitude'], obs_date_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(model_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in observ_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(model_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'longitude': observ_line[:, 0], 'latitude': observ_line[:, 1],\n",
    "                        'lon': matched_lon, 'lat': matched_lat})\n",
    "\n",
    "    model_date_2 = model_data_df.copy()\n",
    "    \n",
    "    total_df = pd.merge(df,data_obs_test,on=['longitude','latitude'])\n",
    "    #print(total_df)\n",
    "\n",
    "    total_df = pd.merge(total_df,model_date_2,on=['lon','lat','hour','day'])\n",
    "    total_df = total_df.drop_duplicates()\n",
    "    road_df = pd.concat([road_df,total_df])\n",
    "    road_df = road_df.drop_duplicates(subset=[\"lon\",\"lat\"])\n",
    "    road_df.to_csv(f\"C:/Users/user/Desktop/모델검증/DATA/test/{road_name}{date}{road_dir_1}_{site}.csv\", index=False)\n",
    "    del road_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR420230120U_jr.csv 5.5023723006194025\n",
      "jr 5.5023723006194025\n",
      "SHR420230120U_mg.csv 6.36220566052734\n",
      "mg 6.36220566052734\n",
      "SHR420230120U_org.csv 4.771968792222207\n",
      "org 4.771968792222207\n",
      "SHR420230120U_ss.csv 0.7131842874426797\n",
      "ss 0.7131842874426797\n",
      "SHR420230120U_yc.csv 0.9572982006230417\n",
      "yc 0.9572982006230417\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a list of CSV file paths named csv_files\n",
    "def cal_rmse_df(site):\n",
    "    csv_files = glob.glob('C:/Users/user/Desktop/모델검증/DATA/test/' + '*.csv')\n",
    "    \n",
    "    df_list = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)  # Use csv_file instead of csv_files\n",
    "        if site in csv_file:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df = df[df['hour'] == 1]\n",
    "            # Check if either 'road temperature100 [°c] cur' or 'surface_temperature' is present\n",
    "            if 'road temperature100 [°c] cur' in df.columns:\n",
    "                # Rename 'road temperature100 [°c] cur' to 'surface_temperature'\n",
    "                df.rename(columns={'road temperature100 [°c] cur': 'surface_temperature'}, inplace=True)\n",
    "            elif 'surface_temperature' in df.columns:\n",
    "                # Do nothing, as the desired column name is already present\n",
    "                pass\n",
    "            else:\n",
    "                # Handle the case when neither column is present if needed\n",
    "                \n",
    "                pass\n",
    "            df_mse = mean_squared_error(df['road_temp'], df['surface_temperature'])\n",
    "            df_rmse = np.sqrt(df_mse)\n",
    "            print(csv_file.split(\"\\\\\")[-1],end=\" \")\n",
    "            print(df_rmse)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenate the list of dataframes into a single dataframe\n",
    "    dfs = pd.concat(df_list, ignore_index=True)  # ignore_index=True resets the index\n",
    "    mse = mean_squared_error(dfs['road_temp'], dfs['surface_temperature'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(site,rmse)\n",
    "    \n",
    "    \n",
    "models  = [\"jr\",\"mg\",\"org\",\"ss\",\"yc\"]\n",
    "for model in models:\n",
    "    cal_rmse_df(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHR4 20230120 U\n"
     ]
    }
   ],
   "source": [
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/sihueng_SHR4_lufft_20230120_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "\n",
    "\n",
    "            \n",
    "# 찾은 CSV 파일들을 출력\n",
    "sites = ['jr','mg','org','ss','yc']\n",
    "for site in sites:\n",
    "    jr_model_file = f\"C:/Users/user/Desktop/모델검증/DATA/MODEL/siheung/{site}/202301/19/KMA_HUFS_ROAD-P_siheung_20230119150000.csv\"\n",
    "    model_road = pd.read_csv(jr_model_file)\n",
    "    cond1 = model_road['road_name'] == road_name\n",
    "    cond2 = model_road['direction'].str.startswith(road_dir_1)\n",
    "    model_road = model_road[cond1&cond2]\n",
    "    #site_list.append(model_road)\n",
    "\n",
    "    model_road['date_time'] = pd.to_datetime(model_road['date_time'])\n",
    "    model_road['hour'] = model_road['date_time'].dt.hour\n",
    "    model_road['day'] = model_road['date_time'].dt.day\n",
    "    cond1 = model_road['lon'] >= 127.0528247\n",
    "    cond2 = model_road['lat'] >= 37.6836121\n",
    "\n",
    "\n",
    "    cond3 = model_road['lon'] >=127.0308726\n",
    "    cond4 = model_road['lon'] <= 127.0339521\n",
    "\n",
    "    cond5 = model_road['lat'] <= 37.5435276\n",
    "    cond6 = model_road['lat'] >= 37.5414698\n",
    "\n",
    "    model_road = model_road[~(cond1 & cond2)]\n",
    "    model_road = model_road[~(cond3 & cond4 & cond5 & cond6)]\n",
    "    model_1 = model_road\n",
    "    \n",
    "\n",
    "    model_data_df = model_1.copy() # 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\n",
    "    obs_date_df = data_obs_test.copy() # 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\n",
    "\n",
    "    #KDTree 를 통한 근접 점 찾기\n",
    "    road_df = pd.DataFrame()\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_date_df['longitude'], obs_date_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(observ_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in model_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(observ_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'lon': model_line[:, 0], 'lat': model_line[:, 1],\n",
    "                        'longitude': matched_lon, 'latitude': matched_lat})\n",
    "\n",
    "    model_date_2 = model_data_df.copy()\n",
    "    \n",
    "    total_df = pd.merge(df,data_obs_test,on=['longitude','latitude'])\n",
    "    #print(total_df)\n",
    "\n",
    "    total_df = pd.merge(total_df,model_date_2,on=['lon','lat','hour','day'])\n",
    "    total_df = total_df.drop_duplicates()\n",
    "    road_df = pd.concat([road_df,total_df])\n",
    "\n",
    "    road_df.to_csv(f\"C:/Users/user/Desktop/모델검증/DATA/{road_name}{date}{road_dir_1}_{site}.csv\", index=False)\n",
    "    del road_df, model_road"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
