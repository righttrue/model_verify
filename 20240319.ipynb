{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "# import cartopy.crs as ccrs\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일별 로드 & 특이사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naebu 20230119 U\n",
      "[19] [16 17]\n"
     ]
    }
   ],
   "source": [
    "#============================================================================================================================================================\n",
    "#seoul_2_naebu_vaisala_20230119_U\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_2_naebu_vaisala_20230119_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "print(data_obs_test[\"day\"].unique(),data_obs_test[\"hour\"].unique())\n",
    "#============================================================================================================================================================\n",
    "#  seoul_1_gangbyeon_vaisala_20230119_U\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_1_gangbyeon_vaisala_20230119_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "\n",
    "\n",
    "# 강병 도로 특이 사항\n",
    "# cond1 = model_road['lon'] >= 126.9061243663102\n",
    "# cond2 = model_road['lat'] <= 37.54867362377485\n",
    "# cond3 = model_road['lon'] <= 126.91043059457456\n",
    "# cond4 = model_road['lat'] >= 37.545676738065886\n",
    "\n",
    "# model_road = model_road[~(cond1 & cond2 & cond3 & cond4)]\n",
    "#============================================================================================================================================================\n",
    "#seoul_3_dongbu_lufft_20230126_D\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_lufft_20230126_D.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "#===================================================================\n",
    "\n",
    "\n",
    "#============================================================================================================================================================\n",
    "#seoul_3_dongbu_lufft_20230127_D.\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_lufft_20230127_D.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "#===================================================================\n",
    "\n",
    "#============================================================================================================================================================\n",
    "#seoul_3_dongbu_lufft_20230127_D.\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_vaisala_20230119_U\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "#==================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongbu 20230126 D\n",
      "[26] [11]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#seoul_2_naebu_vaisala_20230119_U\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_lufft_20230126_D.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "print(data_obs_test[\"day\"].unique(),data_obs_test[\"hour\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 바이살라 _ 중복 해결할 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dongbu 20230119 U\n"
     ]
    }
   ],
   "source": [
    "#seoul_3_dongbu_lufft_20230127_D.\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_3_dongbu_vaisala_20230119_U.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "\n",
    "            \n",
    "# 찾은 CSV 파일들을 출력\n",
    "sites = ['jr','mg','org','ss','yc']\n",
    "for site in sites:\n",
    "    jr_model_file = f\"C:/Users/user/Desktop/모델검증/DATA/MODEL/seoul/{site}/202301/18/KMA_HUFS_ROAD-P_seoul_20230118150000.csv\"\n",
    "    model_road = pd.read_csv(jr_model_file)\n",
    "    cond1 = model_road['road_name'] == road_name\n",
    "    cond2 = model_road['direction'].str.startswith(road_dir_1)\n",
    "    model_road = model_road[cond1&cond2]\n",
    "    #site_list.append(model_road)\n",
    "\n",
    "    model_road['date_time'] = pd.to_datetime(model_road['date_time'])\n",
    "    model_road['hour'] = model_road['date_time'].dt.hour\n",
    "    model_road['day'] = model_road['date_time'].dt.day\n",
    "    # cond1 = model_road['lon'] >= 126.9061243663102\n",
    "    # cond2 = model_road['lat'] <= 37.54867362377485\n",
    "    # cond3 = model_road['lon'] <= 126.91043059457456\n",
    "    # cond4 = model_road['lat'] >= 37.545676738065886\n",
    "\n",
    "    # model_road = model_road[~(cond1 & cond2 & cond3 & cond4)]\n",
    "    model_1 = model_road\n",
    "    \n",
    "\n",
    "    model_data_df = model_1.copy() # 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\n",
    "    obs_date_df = data_obs_test.copy() # 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\n",
    "\n",
    "    #KDTree 를 통한 근접 점 찾기\n",
    "    road_df = pd.DataFrame()\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_date_df['longitude'], obs_date_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(observ_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in model_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(observ_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'lon': model_line[:, 0], 'lat': model_line[:, 1],\n",
    "                        'longitude': matched_lon, 'latitude': matched_lat})\n",
    "\n",
    "    model_date_2 = model_data_df.copy()\n",
    "    \n",
    "    total_df = pd.merge(df,data_obs_test,on=['longitude','latitude'])\n",
    "    #print(total_df)\n",
    "\n",
    "    total_df = pd.merge(total_df,model_date_2,on=['lon','lat','hour','day'])\n",
    "    total_df = total_df.drop_duplicates()\n",
    "    road_df = pd.concat([road_df,total_df])\n",
    "\n",
    "    road_df.to_csv(f\"C:/Users/user/Desktop/모델검증/DATA/{road_name}{date}{road_dir_1}_{site}.csv\", index=False)\n",
    "    del road_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 루프트 _ 중복 문제 해결 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seobu 20230120 D\n",
      "[20] [0]\n"
     ]
    }
   ],
   "source": [
    "#seoul_3_dongbu_lufft_20230127_D.\n",
    "file = \"DATA/20230705_스시2_서울&시흥_1월관측_후처리자료/seoul_4_seobu_lufft_20230120_D.csv\"\n",
    "obs_df = pd.read_csv(file, low_memory=False)\n",
    "obs_df.columns = obs_df.columns.str.lower()\n",
    "\n",
    "file_info = file.split('_')\n",
    "\n",
    "road_name = file_info[-4]\n",
    "date = file_info[-2]\n",
    "road_dir_1 = file_info[-1]\n",
    "road_dir_1 = road_dir_1.split('.')[0]\n",
    "date = file_info[-2]\n",
    "print(road_name, date, road_dir_1)\n",
    "data_obs_test = obs_df\n",
    "data_obs_test[\"timestamp\"] = pd.to_datetime(data_obs_test[\"timestamp\"])\n",
    "data_obs_test[\"year\"] = data_obs_test[\"timestamp\"].dt.year\n",
    "data_obs_test[\"month\"] = data_obs_test[\"timestamp\"].dt.month\n",
    "data_obs_test[\"day\"] = data_obs_test[\"timestamp\"].dt.day\n",
    "data_obs_test[\"hour\"] = data_obs_test[\"timestamp\"].dt.hour\n",
    "print(data_obs_test[\"day\"].unique(),data_obs_test[\"hour\"].unique())\n",
    "#관측 자료 특이사항 제거\n",
    "\n",
    "            \n",
    "# 찾은 CSV 파일들을 출력\n",
    "sites = ['jr','mg','org','ss','yc']\n",
    "for site in sites:\n",
    "    jr_model_file = f\"C:/Users/user/Desktop/모델검증/DATA/MODEL/seoul/{site}/202301/19/KMA_HUFS_ROAD-P_seoul_20230119150000.csv\"\n",
    "    model_road = pd.read_csv(jr_model_file)\n",
    "    cond1 = model_road['road_name'] == road_name\n",
    "    cond2 = model_road['direction'].str.startswith(road_dir_1)\n",
    "    model_road = model_road[cond1&cond2]\n",
    "    #site_list.append(model_road)\n",
    "\n",
    "    model_road['date_time'] = pd.to_datetime(model_road['date_time'])\n",
    "    model_road['hour'] = model_road['date_time'].dt.hour\n",
    "    model_road['day'] = model_road['date_time'].dt.day\n",
    "    model_1 = model_road\n",
    "    \n",
    "\n",
    "    model_data_df = model_1.copy() # 해당 조건의 모델 데이터 / 재사용을 위해 복사본 사용\n",
    "    obs_date_df = data_obs_test.copy() # 해당 조건의 관측 데이터 / 재사용을 위해 복사본 사용\n",
    "\n",
    "    #KDTree 를 통한 근접 점 찾기\n",
    "    road_df = pd.DataFrame()\n",
    "    # 첫 번째 줄의 위경도 데이터\n",
    "    observ_line = np.array(list(zip(obs_date_df['longitude'], obs_date_df['latitude'])))\n",
    "\n",
    "    # 두 번째 줄의 위경도 데이터\n",
    "    model_line = np.array(list(zip(model_data_df['lon'], model_data_df['lat'])))\n",
    "\n",
    "    # KDTree 객체 생성\n",
    "    tree = KDTree(model_line)\n",
    "\n",
    "    # 각 점마다 가장 가까운 점을 찾아 매칭\n",
    "    matched_points = []\n",
    "    for point in observ_line:\n",
    "        _, index = tree.query([point], k=1)  # k=1로 설정하여 가장 가까운 점 하나만 선택\n",
    "        matched_points.append(model_line[index[0]])\n",
    "\n",
    "    matched_lon = [point[0][0] for point in matched_points]\n",
    "    matched_lat = [point[0][1] for point in matched_points]\n",
    "\n",
    "    df = pd.DataFrame({'longitude': observ_line[:, 0], 'latitude': observ_line[:, 1],\n",
    "                        'lon': matched_lon, 'lat': matched_lat})\n",
    "\n",
    "    model_date_2 = model_data_df.copy()\n",
    "    \n",
    "    total_df = pd.merge(df,data_obs_test,on=['longitude','latitude'])\n",
    "    #print(total_df)\n",
    "\n",
    "    total_df = pd.merge(total_df,model_date_2,on=['lon','lat','hour','day'])\n",
    "    total_df = total_df.drop_duplicates()\n",
    "    road_df = pd.concat([road_df,total_df])\n",
    "\n",
    "    road_df.to_csv(f\"C:/Users/user/Desktop/모델검증/DATA/{road_name}{date}{road_dir_1}_{site}.csv\", index=False)\n",
    "    del road_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE 계산 _ 폴더별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seobu20230120D_jr.csv 3.1962997721153634\n",
      "jr 3.1962997721153634\n",
      "seobu20230120D_mg.csv 3.8612301895933268\n",
      "mg 3.8612301895933268\n",
      "seobu20230120D_org.csv 4.057816343712038\n",
      "org 4.057816343712038\n",
      "seobu20230120D_ss.csv 1.9316369093092365\n",
      "ss 1.9316369093092365\n",
      "seobu20230120D_yc.csv 1.6785652928026622\n",
      "yc 1.6785652928026622\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a list of CSV file paths named csv_files\n",
    "def cal_rmse_df(site):\n",
    "    csv_files = glob.glob('C:/Users/user/Desktop/모델검증/DATA/veri/seobu/' + '*.csv')\n",
    "    \n",
    "    df_list = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)  # Use csv_file instead of csv_files\n",
    "        if site in csv_file:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # Check if either 'road temperature100 [°c] cur' or 'surface_temperature' is present\n",
    "            if 'road temperature100 [°c] cur' in df.columns:\n",
    "                # Rename 'road temperature100 [°c] cur' to 'surface_temperature'\n",
    "                df.rename(columns={'road temperature100 [°c] cur': 'surface_temperature'}, inplace=True)\n",
    "            elif 'surface_temperature' in df.columns:\n",
    "                # Do nothing, as the desired column name is already present\n",
    "                pass\n",
    "            else:\n",
    "                # Handle the case when neither column is present if needed\n",
    "                \n",
    "                pass\n",
    "            df_mse = mean_squared_error(df['road_temp'], df['surface_temperature'])\n",
    "            df_rmse = np.sqrt(df_mse)\n",
    "            print(csv_file.split(\"\\\\\")[-1],end=\" \")\n",
    "            print(df_rmse)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenate the list of dataframes into a single dataframe\n",
    "    dfs = pd.concat(df_list, ignore_index=True)  # ignore_index=True resets the index\n",
    "    mse = mean_squared_error(dfs['road_temp'], dfs['surface_temperature'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(site,rmse)\n",
    "    \n",
    "    \n",
    "models  = [\"jr\",\"mg\",\"org\",\"ss\",\"yc\"]\n",
    "for model in models:\n",
    "    cal_rmse_df(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naebu20230119U_jr.csv 4.220169134190787\n",
      "jr 4.220169134190787\n",
      "naebu20230119U_mg.csv 6.152160626986038\n",
      "mg 6.152160626986038\n",
      "naebu20230119U_org.csv 2.5186612749804893\n",
      "org 2.5186612749804893\n",
      "naebu20230119U_ss.csv 2.331589435991559\n",
      "ss 2.331589435991559\n",
      "naebu20230119U_yc.csv 2.332677467883367\n",
      "yc 2.332677467883367\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a list of CSV file paths named csv_files\n",
    "def cal_rmse_df(site):\n",
    "    csv_files = glob.glob('C:/Users/user/Desktop/모델검증/DATA/veri/naebu/' + '*.csv')\n",
    "    \n",
    "    df_list = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)  # Use csv_file instead of csv_files\n",
    "        if site in csv_file:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df = df[df['hour'] == 17]\n",
    "            # Check if either 'road temperature100 [°c] cur' or 'surface_temperature' is present\n",
    "            if 'road temperature100 [°c] cur' in df.columns:\n",
    "                # Rename 'road temperature100 [°c] cur' to 'surface_temperature'\n",
    "                df.rename(columns={'road temperature100 [°c] cur': 'surface_temperature'}, inplace=True)\n",
    "            elif 'surface_temperature' in df.columns:\n",
    "                # Do nothing, as the desired column name is already present\n",
    "                pass\n",
    "            else:\n",
    "                # Handle the case when neither column is present if needed\n",
    "                \n",
    "                pass\n",
    "            df_mse = mean_squared_error(df['road_temp'], df['surface_temperature'])\n",
    "            df_rmse = np.sqrt(df_mse)\n",
    "            print(csv_file.split(\"\\\\\")[-1],end=\" \")\n",
    "            print(df_rmse)\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenate the list of dataframes into a single dataframe\n",
    "    dfs = pd.concat(df_list, ignore_index=True)  # ignore_index=True resets the index\n",
    "    mse = mean_squared_error(dfs['road_temp'], dfs['surface_temperature'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(site,rmse)\n",
    "    \n",
    "    \n",
    "models  = [\"jr\",\"mg\",\"org\",\"ss\",\"yc\"]\n",
    "for model in models:\n",
    "    cal_rmse_df(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
